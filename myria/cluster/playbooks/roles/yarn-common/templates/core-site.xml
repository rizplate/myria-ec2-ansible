<configuration>
  <!-- <property>
    <name>fs.http.impl</name>
    <value>org.apache.samza.util.hadoop.HttpFileSystem</value>
  </property> -->
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://{{ master_ip }}:8020</value>
  </property>

  <property>
    <name>hadoop.tmp.dir</name>
    <value>{{ hadoop_home }}/tmp</value>
  </property>

  <property>
    <name>fs.s3a.impl</name>
    <value>org.apache.hadoop.fs.s3a.S3AFileSystem</value>
    <description>The implementation class of the S3A Filesystem</description>
  </property>

  <property>
    <name>fs.s3a.aws.credentials.provider</name>
    <value>
{% if ROLE is defined %}
    com.amazonaws.auth.InstanceProfileCredentialsProvider
{% else %}
    org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider
{% endif %}
    </value>
  </property>

  <property>
    <name>fs.s3a.connection.maximum</name>
    <value>1500</value>
    <description>Controls the maximum number of simultaneous connections to S3.</description>
  </property>

  <!-- should significantly improve perf esp. for lots of small files, see e.g.
       http://improve.dk/pushing-the-limits-of-amazon-s3-upload-performance/
  -->
  <property>
    <name>fs.s3a.connection.ssl.enabled</name>
    <value>false</value>
    <description>Enables or disables SSL connections to S3.</description>
  </property>

  <property>
    <name>fs.s3a.endpoint</name>
    <description>AWS S3 endpoint to connect to. An up-to-date list is
      provided in the AWS Documentation: regions and endpoints. Without this
      property, the standard region (s3.amazonaws.com) is assumed.
    </description>
  </property>

  <property>
    <name>fs.s3a.proxy.host</name>
    <description>Hostname of the (optional) proxy server for S3 connections.</description>
  </property>

  <property>
    <name>fs.s3a.proxy.port</name>
    <description>Proxy server port. If this property is not set
      but fs.s3a.proxy.host is, port 80 or 443 is assumed (consistent with
      the value of fs.s3a.connection.ssl.enabled).</description>
  </property>

  <property>
    <name>fs.s3a.proxy.username</name>
    <description>Username for authenticating with proxy server.</description>
  </property>

  <property>
    <name>fs.s3a.proxy.password</name>
    <description>Password for authenticating with proxy server.</description>
  </property>

  <property>
    <name>fs.s3a.proxy.domain</name>
    <description>Domain for authenticating with proxy server.</description>
  </property>

  <property>
    <name>fs.s3a.proxy.workstation</name>
    <description>Workstation for authenticating with proxy server.</description>
  </property>

  <property>
    <name>fs.s3a.attempts.maximum</name>
    <value>10</value>
    <description>How many times we should retry commands on transient errors.</description>
  </property>

  <property>
    <name>fs.s3a.connection.establish.timeout</name>
    <value>5000</value>
    <description>Socket connection setup timeout in milliseconds.</description>
  </property>

  <property>
    <name>fs.s3a.connection.timeout</name>
    <value>50000</value>
    <description>Socket connection timeout in milliseconds.</description>
  </property>

  <property>
    <name>fs.s3a.paging.maximum</name>
    <value>5000</value>
    <description>How many keys to request from S3 when doing
       directory listings at a time.</description>
  </property>

  <property>
    <name>fs.s3a.threads.max</name>
    <value>256</value>
    <description> Maximum number of concurrent active (part)uploads,
    which each use a thread from the threadpool.</description>
  </property>

  <property>
    <name>fs.s3a.threads.core</name>
    <value>15</value>
    <description>Number of core threads in the threadpool.</description>
  </property>

  <property>
    <name>fs.s3a.threads.keepalivetime</name>
    <value>60</value>
    <description>Number of seconds a thread can be idle before being
      terminated.</description>
  </property>

  <property>
    <name>fs.s3a.max.total.tasks</name>
    <value>1000</value>
    <description>Number of (part)uploads allowed to the queue before
    blocking additional uploads.</description>
  </property>

  <property>
    <name>fs.s3a.multipart.size</name>
    <value>104857600</value>
    <description>How big (in bytes) to split upload or copy operations up into.</description>
  </property>

  <property>
    <name>fs.s3a.multipart.threshold</name>
    <value>2147483647</value>
    <description>Threshold before uploads or copies use parallel multipart operations.</description>
  </property>

  <property>
    <name>fs.s3a.acl.default</name>
    <description>Set a canned ACL for newly created and copied objects. Value may be private,
       public-read, public-read-write, authenticated-read, log-delivery-write,
       bucket-owner-read, or bucket-owner-full-control.</description>
  </property>

  <property>
    <name>fs.s3a.multipart.purge</name>
    <value>false</value>
    <description>True if you want to purge existing multipart uploads that may not have been
       completed/aborted correctly</description>
  </property>

  <property>
    <name>fs.s3a.multipart.purge.age</name>
    <value>86400</value>
    <description>Minimum age in seconds of multipart uploads to purge</description>
  </property>

  <property>
    <name>fs.s3a.buffer.dir</name>
    <value>${hadoop.tmp.dir}/s3a</value>
    <description>Comma separated list of directories that will be used to buffer file
      uploads to. No effect if fs.s3a.fast.upload is true.</description>
  </property>

  <!-- need to experiment with defaults and possibly change them based on instance type -->
  <property>
    <name>fs.s3a.fast.upload</name>
    <value>true</value>
    <description>Upload directly from memory instead of buffering to
    disk first. Memory usage and parallelism can be controlled as up to
    fs.s3a.multipart.size memory is consumed for each (part)upload actively
    uploading (fs.s3a.threads.max) or queueing (fs.s3a.max.total.tasks)</description>
  </property>

  <property>
    <name>fs.s3a.fast.buffer.size</name>
    <value>1048576</value>
    <description>Size (in bytes) of initial memory buffer allocated for an
    upload. No effect if fs.s3a.fast.upload is false.</description>
  </property>
</configuration>
